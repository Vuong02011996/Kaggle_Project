# 2 solution - Yao
+ I had already wrote the biggest secret here, that two stage training!
+ **two stage training**: First pretrain on Kaggle-Persuade data, then load the weights and train on Kaggle-Only data.
+ Yes. 2-stage helps a lot. Its boost my LB from 0.80+ to 0.824+ esaily. I have best single model with PB 0.836
+ Thank you! **I dont have additional text features** and its only DeBERTa models
+ Thank you Chris! Its only ensemble of DeBERTa. But some of my single model seems better than my many weighted blend ensemble.
+  I used a similar strategy with you: paying more attention to Kaggle-Persuade(A) + Kaggle-Only(B) set. I think this is the key for final score.

# 1 solution
+ Fast Ultra Fast QWK Calc Method
  + https://www.kaggle.com/code/cpmpml/ultra-fast-qwk-calc-method
    
